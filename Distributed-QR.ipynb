{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c612b769",
   "metadata": {},
   "source": [
    "- Guillermo Benito Calvino - 2072106\n",
    "- Leon Mengoni - 2091185\n",
    "- Filippo Pra Floriani - 2089902"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18766247",
   "metadata": {},
   "source": [
    "# Project - Distributed Algorithms\n",
    "# Dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b15a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "import dask.array as da\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import graphviz\n",
    "import time\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8623f80e",
   "metadata": {},
   "source": [
    "## CLUSTER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdc6b74",
   "metadata": {},
   "source": [
    "We have created a cluster where 1 virtual machine acts as a schedueler and a worker and the other two VM are only workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085d3a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_remote = False\n",
    "in_local = True\n",
    "\n",
    "if in_remote:\n",
    "    client = Client('10.67.22.67:8786') # solo la porta dello scheduler\n",
    "    client\n",
    "\n",
    "if in_local:\n",
    "    client = Client('dask-scheduler:8786')\n",
    "    client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ffce3c",
   "metadata": {},
   "source": [
    "## QR DECOMPOSITION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3cec3d",
   "metadata": {},
   "source": [
    "### Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e42335",
   "metadata": {},
   "source": [
    "Factorize $A$ matrix in $$A = QR$$\n",
    "\n",
    "- $A$ matrix *m x n*\n",
    "- $Q$ orthogonal matrix *m x n*\n",
    "- $R$ upper triangular matrix *n x n*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c00be79",
   "metadata": {},
   "source": [
    "### Indirect method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c39f74c",
   "metadata": {},
   "source": [
    "We are working with *tall and skinny* matrices: $m >> n$.\n",
    "\n",
    "\n",
    "The matrix $R$ is fast computed with MapReduce methods, instead the matrix $Q$ is computed **indirectly** as $$Q = AR^{-1}$$ for $R$ invertible and $A$ full rank.\n",
    "\n",
    "This method is numerically unstable since the calculated Q is not exactly orthogonal. To measured this error, we use: $$ || Q^{T}Q - I||_2$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89274c1c",
   "metadata": {},
   "source": [
    "### Direct method (TSQR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d8f355",
   "metadata": {},
   "source": [
    "In https://arxiv.org/abs/1301.1071 they propose a *direct* method for calculation Q wich is not unestable called *DIRECT TSQR*. \n",
    "\n",
    "The main goal of this project is to implement this method and check it performance with two success metrics:\n",
    "\n",
    "- *accuracy* of decomposition, we use     $||A âˆ’ QR||_2/|R|_2$\n",
    "- *orthogonality* of computed $Q$ factor, we use     $|| Q^{T}Q - I||_2$\n",
    "\n",
    "The ideal value for both metrics is 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46dda438",
   "metadata": {},
   "source": [
    "#### First step: `Map tasks`\n",
    "We are going to work with dask arrays.\n",
    "\n",
    "- Divide the data in different chunks. Since the matrix is tall and skinny, the chunks consist in all the columns and a certain number of rows. (For explainatory puorposes we divide A in for blocks such that $A_i$ is $\\frac{m}{n}xn$)\n",
    "- Compute QR decomposition and emits $Q$ and $R$ separately to each block\n",
    "\n",
    "$$\n",
    "A = \\left [ \\begin{matrix}\n",
    "   A_1 \\\\\n",
    "   A_2 \\\\\n",
    "   A_3 \\\\\n",
    "   A_4 \\\\\n",
    "\\end{matrix}\\right ]\n",
    "=\\left [ \\begin{matrix}\n",
    "   Q_1 & 0 & 0 & 0 \\\\\n",
    "    0 & Q_2 & 0 & 0 \\\\\n",
    "    0 & 0 & Q_3 & 0 \\\\\n",
    "    0 & 0 & 0 & Q_4 \\\\\n",
    "\\end{matrix} \\right ]\n",
    "\\quad\n",
    "\\left [ \\begin{matrix}\n",
    "   R_1 \\\\\n",
    "   R_2 \\\\\n",
    "   R_3 \\\\\n",
    "   R_4 \\\\\n",
    "\\end{matrix} \\right ]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22a7eed",
   "metadata": {},
   "source": [
    "#### Second step: `Reduce task`\n",
    "\n",
    "- The input is the set of $R$ factors from the first step\n",
    "- $R$ factors are collected as a matrix\n",
    "- Compute QR decomposition and emit $Q$ factor\n",
    "- $\\tilde{R}$ is the final $R$ matrix of the whole QR decomposition\n",
    "\n",
    "$$\n",
    "\\left [ \\begin{matrix}\n",
    "    R_1 \\\\\n",
    "    R_2 \\\\\n",
    "    R_3 \\\\\n",
    "    R_4 \\\\\n",
    "\\end{matrix} \\right ] = \\left [ \\begin{matrix}\n",
    "    Q^2_1 \\\\\n",
    "    Q^2_2 \\\\\n",
    "    Q^2_3 \\\\\n",
    "    Q^2_4 \\\\\n",
    "\\end{matrix} \\right ]\n",
    "\\tilde{R}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b661de",
   "metadata": {},
   "source": [
    "#### Third step: `Map tasks`\n",
    "\n",
    "- The input is the set of $Q$ factors from the first step\n",
    "- $Q^2$ factors are distributed to all map tasks\n",
    "- Multiply the corresponding $Q$ factors from first and second step and emit the final $Q$\n",
    "\n",
    "$$\n",
    "Q = \\left [ \\begin{matrix}\n",
    "   Q_1 & 0 & 0 & 0 \\\\\n",
    "    0 & Q_2 & 0 & 0 \\\\\n",
    "    0 & 0 & Q_3 & 0 \\\\\n",
    "    0 & 0 & 0 & Q_4 \\\\\n",
    "\\end{matrix} \\right ]\n",
    "\\quad\n",
    "\\left [ \\begin{matrix}\n",
    "   Q^2_1 \\\\\n",
    "   Q^2_2 \\\\\n",
    "   Q^2_3 \\\\\n",
    "   Q^2_4 \\\\\n",
    "\\end{matrix} \\right ]\n",
    "=\n",
    "\\left [ \\begin{matrix}\n",
    "   Q_1 Q^2_1 \\\\\n",
    "   Q_2 Q^2_2 \\\\\n",
    "   Q_3 Q^2_3 \\\\\n",
    "   Q_4 Q^2_4 \\\\\n",
    "\\end{matrix} \\right ]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec25c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def direct_TSQR(data,num_blocks,is_random):\n",
    "    \n",
    "    ## FIRST STEP    \n",
    "    if is_random:\n",
    "        dA = data\n",
    "        \n",
    "        dim = data.shape\n",
    "        columns = dim[1]\n",
    "        rows = dim[0]\n",
    "        rows_per_block = rows//num_blocks  # how many rows each block has\n",
    "\n",
    "        chunk_list = [rows_per_block]*num_blocks\n",
    "        chunk_list[-1] = rows_per_block - (rows_per_block*num_blocks - rows)\n",
    "        chunk_list = tuple(chunk_list)\n",
    "        \n",
    "        dA = data.rechunk((chunk_list, (columns,)))\n",
    "        dask_housing = dA\n",
    "    else:\n",
    "        \n",
    "        dim = data.shape\n",
    "        columns = dim[1]\n",
    "        rows = dim[0]\n",
    "        rows_per_block = rows//num_blocks  # how many rows each block has\n",
    "\n",
    "        chunk_list = [rows_per_block]*num_blocks\n",
    "        chunk_list[-1] = rows_per_block - (rows_per_block*num_blocks - rows)\n",
    "        chunk_list = tuple(chunk_list)\n",
    "        \n",
    "        dA = da.from_array(data, chunks=((chunk_list, (columns,)))) #divide the data in bloks\n",
    "        dask_housing = dA\n",
    "    \n",
    "    step1_R = dA.map_blocks(lambda x: np.linalg.qr(x)[1],chunks=(columns,columns)) #calculate every R_i.\n",
    "    \n",
    "    step1_Q =dA.map_blocks(lambda x: np.linalg.qr(x)[0],chunks=(chunk_list,(columns,))) #calculate every Q_i \n",
    "    ##!!The final shape is a column block matrix (such as with R_i) not a diagonal block matrix \n",
    "    ##(as displayed in the theoretical explanaiton)!!\n",
    "    \n",
    "    ##SECOND STEP\n",
    "    input_R = step1_R.rechunk(num_blocks*columns,columns) ## Merge the diferent blocks R_i into a unique block R\n",
    "    R = np.linalg.qr(input_R)[1] # Calculate final R. No need for map_block since there is no block partition\n",
    "    \n",
    "    step2_Q = input_R.map_blocks(lambda x: np.linalg.qr(x)[0],chunks=(num_blocks*columns,columns)).rechunk(columns,columns)\n",
    "    ## Again column block matrix of Q^2_i\n",
    "    \n",
    "    ##THIRD SETP\n",
    "    Q = da.map_blocks(lambda x,y: np.matmul(x,y),step1_Q,step2_Q) #matrix multiplication block by block. [0:rows] is to\n",
    "    # throw away the possible exceding rows if rows/num_blocks does not yield a hole number.\n",
    "    return(dask_housing, Q, R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d842b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Succes metrics\n",
    "def accuracy(data,Q,R):\n",
    "    accuracy = da.linalg.norm(data - da.matmul(Q, R))/da.linalg.norm(R)\n",
    "    return(accuracy)\n",
    "def orthogonality(Q):\n",
    "    columns=Q.shape[1]\n",
    "    ortho= da.linalg.norm(da.matmul(Q.T, Q)- np.eye(columns))\n",
    "    return(ortho)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8865a99f",
   "metadata": {},
   "source": [
    "## DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b12b1b",
   "metadata": {},
   "source": [
    "We will work with two different data:\n",
    "- California housing dataset (from sklearn)\n",
    "- Random generated matrices of different sizes.\n",
    "\n",
    "We choose to work also with the second kind since the first dataset is small.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a80337",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Housing data\n",
    "data_house = datasets.fetch_california_housing()\n",
    "df = pd.DataFrame(data=data_house.data, columns=data_house.feature_names)\n",
    "data_matrix = np.array(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3385f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4b9b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "## random data\n",
    "def random_data(rows,columns):\n",
    "    dask_random= da.random.random((rows,columns))\n",
    "    return(dask_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76f632f",
   "metadata": {},
   "source": [
    "## RESULTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4278f4de",
   "metadata": {},
   "source": [
    "First of all we want to have a look at our algorithm for a simple examples such as housing data and 4 blocks,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab365b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_blocks_example = 4\n",
    "A_example, Q_example,R_example=direct_TSQR(data_matrix, num_blocks_example, is_random = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bb3518",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Q_example.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6394db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "R_example.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8386f962",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_example = accuracy(A_example, Q_example, R_example).compute()\n",
    "orthogonality_example = orthogonality(Q_example).compute()\n",
    "\n",
    "print('Accuracy: ', accuracy_example)\n",
    "print('\\nOrthogonality: ', orthogonality_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8169873",
   "metadata": {},
   "source": [
    "Next step is to check if different number of blocks yield good results regarding our success metrics.  \n",
    "\n",
    "We will use the housing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b5e18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_blocks_list = [2,4,10,20,50,100,150]\n",
    "accuracy_list = np.zeros(len(num_blocks_list))\n",
    "orthogonality_list = np.zeros(len(num_blocks_list))\n",
    "\n",
    "for i in range(len(num_blocks_list)):\n",
    "    dask_housing, Q, R = direct_TSQR(data_matrix, num_blocks_list[i], is_random = False)\n",
    "    accuracy_list[i] = accuracy(dask_housing, Q, R).compute()\n",
    "    orthogonality_list[i] = orthogonality(Q).compute()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bfcfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(num_blocks_list, orthogonality_list, 'o', linestyle='dotted',label='$|| Q^{T}Q - I||_2$')\n",
    "plt.plot(num_blocks_list, accuracy_list, 'o', linestyle='dotted',label='$||A âˆ’ QR||_2/|R|_2$')\n",
    "plt.xlabel('# of blocks')\n",
    "plt.ylabel('Values')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a5af02",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_n, R_n=np.linalg.qr(data_matrix)\n",
    "ortho_normal=np.linalg.norm(Q_n.T@Q_n - np.eye(Q_n.shape[1]))\n",
    "acc_normal=np.linalg.norm(Q_n@R_n - data_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ed3d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy for non paralelized QR decomposition:',acc_normal)\n",
    "print('\\nOrthogonality for non paralelized QR decomposition:',ortho_normal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3566b3b",
   "metadata": {},
   "source": [
    "Even though the best choice seems to be 20 blocks, all the different partitions yield really good results of the order of $10^{-15}$. We can see also that the direct TSQR method is more accurate than the non paralelized QR.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d886f4b9",
   "metadata": {},
   "source": [
    "Knowing that all partitions are correct, we want to find which one is the fastest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e00703",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_blocks_list=[2,4,10,20,50,100,150]\n",
    "time_list=np.zeros(len(num_blocks_list))\n",
    "for i in range(len(num_blocks_list)):\n",
    "    start = time.time()\n",
    "    A, Q, R = direct_TSQR(data_matrix,num_blocks_list[i], is_random = False)\n",
    "    R_ = R.compute()\n",
    "    Q_ = Q.compute()\n",
    "    end = time.time()\n",
    "    time_list[i] = ((end - start)*1000)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62598754",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(num_blocks_list, time_list, 'o', linestyle='dotted')\n",
    "plt.xlabel('# of blocks')\n",
    "plt.ylabel('time [ms]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2629231c",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "normal_qr=np.linalg.qr(data_matrix)\n",
    "\n",
    "end = time.time()\n",
    "time_normal=((end - start)*1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3047377f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Minimum time for direct TSQR:',round(min(time_list)),'ms')\n",
    "print('\\nTime for normal QR descomposition (no partition):',round(time_normal),'ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2398c1",
   "metadata": {},
   "source": [
    "We can observe that the less number of blocks the better. In fact doing no partition at all is way faster. This is due to the time required to split the data and schedule the tasks. Theoretically the implemented algotirthm should be faster than the regular QR descomposition for bigger datasets. To prove so we are going to work with bigger matrices generated randomly. We will fix the number of columns and vary the number of rows since we are constantly working with tall and skinny matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424d1a5e",
   "metadata": {},
   "source": [
    "From now on we want to make a differentation between using the numpy function qr, which does not take advantage of the paralelization and its adaptation to dask. The second one uses paralelization but it is different from the algorithm that we implemented.  \n",
    "We will call them as follows:\n",
    "- **numpy.linalg.qr** (no paralelization): Normal QR\n",
    "- **dask.array.linalg.qr** (adaptation of numpy function to dask): Dask QR\n",
    "- The implemented algorithm: **Direct TSQR** (as before)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3b6c26",
   "metadata": {},
   "source": [
    "We shall start as before, searching which is the best number of blocks for our algorithm. Later we will be able to compare all 3 methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af93b0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create data:\n",
    "rows = int(1e6)\n",
    "columns = 20\n",
    "data = random_data(rows,columns)\n",
    "\n",
    "num_blocks_list = [2,4,10,20,50,100]\n",
    "accuracy_list = np.zeros(len(num_blocks_list))\n",
    "orthogonality_list = np.zeros(len(num_blocks_list))\n",
    "\n",
    "for i in range(len(num_blocks_list)):\n",
    "    A, Q, R = direct_TSQR(data, num_blocks_list[i], is_random = True)\n",
    "    accuracy_list[i] = accuracy(data, Q, R).compute()\n",
    "    orthogonality_list[i] = orthogonality(Q).compute()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eada129d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.plot(num_blocks_list, orthogonality_list, 'o', linestyle='dotted',label='$|| Q^{T}Q - I||_2$')\n",
    "plt.plot(num_blocks_list, accuracy_list, 'o', linestyle='dotted',label='$||A âˆ’ QR||_2/|R|_2$')\n",
    "plt.xlabel('# of blocks')\n",
    "plt.ylabel('Values')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7de2d89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Q,R = np.linalg.qr(data)\n",
    "acc_dask = accuracy(data, Q, R).compute()\n",
    "ortho_dask = orthogonality(Q).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4903a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy for dask QR:',acc_dask)\n",
    "print('\\nOrthogonality for dask QR:',ortho_dask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4285d2e4",
   "metadata": {},
   "source": [
    "We can see that now the success metrics get better with more partitions. Nevertheless the values are good for all type of divisions.\n",
    "\n",
    "The accuracy for the dask QR is a little bit higher than for the direct method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c5ff95",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_blocks_list=[2,4,10,20,50,100,150]\n",
    "time_list=np.zeros(len(num_blocks_list))\n",
    "for i in range(len(num_blocks_list)):\n",
    "    start = time.time()\n",
    "    A, Q, R = direct_TSQR(data, num_blocks_list[i], is_random = True)\n",
    "    R_ = R.compute()\n",
    "    Q_ = Q.compute()\n",
    "    end = time.time()\n",
    "    time_list[i] = ((end - start)*1000)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a86074",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.plot(num_blocks_list, time_list, 'o', linestyle='dotted')\n",
    "plt.xlabel('# of blocks')\n",
    "plt.ylabel('time [ms]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df711467",
   "metadata": {},
   "source": [
    "In this case we can see that there is a minimum for 50 blocks. This corresponds to take around 20000 rows per every block. We will use this value as reference when scaling the dataset size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3d211d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_list=np.array([1e5,5e5,1e6,5e6,1e7]) ## 1e8??\n",
    "columns2 = 20\n",
    "\n",
    "rows_per_block = 20000 ### Value calculated previously\n",
    "num_blocks = rows_list//rows_per_block\n",
    "\n",
    "time_list_direct = np.zeros(len(rows_list))\n",
    "time_list_normal = np.zeros(len(rows_list[rows_list<1e6]))\n",
    "time_list_dask = np.zeros(len(rows_list))\n",
    "\n",
    "for i in range(len(rows_list)):\n",
    "    \n",
    "    #direct TSQR\n",
    "    data = random_data(int(rows_list[i]), columns)\n",
    "    start = time.time()\n",
    "    A, Q, R=direct_TSQR(data, int(num_blocks[i]), is_random = True)\n",
    "    Q_ = Q.compute()\n",
    "    R_ = R.compute()\n",
    "    end = time.time()\n",
    "    time_list_direct[i] = ((end - start)*1000)\n",
    "    \n",
    "    #dask qr\n",
    "    dask_data = da.random.random((rows_list[i], columns))\n",
    "    start = time.time()\n",
    "    Q_normal,R_normal=np.linalg.qr(dask_data)\n",
    "    Q_ = Q.compute()\n",
    "    R_ = R.compute()\n",
    "    end = time.time()\n",
    "    time_list_dask[i] = ((end - start)*1000)\n",
    "    \n",
    "    #normal qr\n",
    "    if rows_list[i]<1e6: ## for bigger matrices normal qr can not compute\n",
    "        numpy_data=np.random.random((int(rows_list[i]),columns))\n",
    "        start = time.time()\n",
    "        Q,R=np.linalg.qr(numpy_data) \n",
    "        end = time.time()\n",
    "        time_list_dask[i]=((end - start)*1000)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc5a7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(rows_list,time_list_dask,'o', linestyle='dotted',label='Dask QR')\n",
    "plt.plot(rows_list,time_list_direct,'o', linestyle='dotted',label='Direct TSQR')\n",
    "plt.plot(rows_list[rows_list<1e6],time_list_normal,'o', linestyle='dotted',label='Normal QR')\n",
    "plt.xscale('log')\n",
    "plt.xlabel('# of rows of the hole matrix')\n",
    "plt.ylabel('time [ms]')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5d15b7",
   "metadata": {},
   "source": [
    "The fastest method is still without paralelizing for the same reason we mentioned before. The downside of this method is that it can not operate with too heavy matrices.   \n",
    "On the other hand both methods that use paralelization have the same speed. Between these two method, the direct TSQR is superior since its accuracy is $3$ times smaller. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c0e60a",
   "metadata": {},
   "source": [
    "Lastly we would like to try using one persist to see if the time reduces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807f26df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def direct_TSQR_persist(data,num_blocks,is_random):\n",
    "    \n",
    "    ## FIRST STEP    \n",
    "    if is_random:\n",
    "        dA = data\n",
    "        \n",
    "        dim = data.shape\n",
    "        columns = dim[1]\n",
    "        rows = dim[0]\n",
    "        rows_per_block = rows//num_blocks  # how many rows each block has\n",
    "\n",
    "        chunk_list = [rows_per_block]*num_blocks\n",
    "        chunk_list[-1] = rows_per_block - (rows_per_block*num_blocks - rows)\n",
    "        chunk_list = tuple(chunk_list)\n",
    "        \n",
    "        dA = data.rechunk((chunk_list, (columns,)))\n",
    "        dask_housing = dA\n",
    "    else:\n",
    "        \n",
    "        dim = data.shape\n",
    "        columns = dim[1]\n",
    "        rows = dim[0]\n",
    "        rows_per_block = rows//num_blocks  # how many rows each block has\n",
    "\n",
    "        chunk_list = [rows_per_block]*num_blocks\n",
    "        chunk_list[-1] = rows_per_block - (rows_per_block*num_blocks - rows)\n",
    "        chunk_list = tuple(chunk_list)\n",
    "        \n",
    "        dA = da.from_array(data, chunks=((chunk_list, (columns,)))) #divide the data in bloks\n",
    "        dask_housing = dA\n",
    "    \n",
    "    step1_R = dA.map_blocks(lambda x: np.linalg.qr(x)[1],chunks=(columns,columns)) #calculate every R_i.\n",
    "    \n",
    "    step1_Q =dA.map_blocks(lambda x: np.linalg.qr(x)[0],chunks=(chunk_list,(columns,))) #calculate every Q_i \n",
    "    ##!!The final shape is a column block matrix (such as with R_i) not a diagonal block matrix \n",
    "    ##(as displayed in the theoretical explanaiton)!!\n",
    "    \n",
    "    ##SECOND STEP\n",
    "    input_R = step1_R.rechunk(num_blocks*columns,columns).persist() ## Merge the diferent blocks R_i into a unique block R\n",
    "    R = np.linalg.qr(input_R)[1] # Calculate final R. No need for map_block since there is no block partition\n",
    "    \n",
    "    step2_Q = input_R.map_blocks(lambda x: np.linalg.qr(x)[0],chunks=(num_blocks*columns,columns)).rechunk(columns,columns)\n",
    "    ## Again column block matrix of Q^2_i\n",
    "    \n",
    "    ##THIRD SETP\n",
    "    Q = da.map_blocks(lambda x,y: np.matmul(x,y),step1_Q,step2_Q) #matrix multiplication block by block. [0:rows] is to\n",
    "    # throw away the possible exceding rows if rows/num_blocks does not yield a hole number.\n",
    "    return(dask_housing, Q, R, input_R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25247b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_list=np.array([1e5,5e5,1e6,5e6,1e7]) ## 1e8??\n",
    "columns2 = 20\n",
    "\n",
    "rows_per_block = 20000 ### Value calculated previously\n",
    "num_blocks = rows_list//rows_per_block\n",
    "\n",
    "time_list_persist = np.zeros(len(rows_list))\n",
    "memory_relative = np.zeros(len(rows_list))\n",
    "for i in range(len(rows_list)):\n",
    "    \n",
    "    #direct TSQR\n",
    "    data = random_data(int(rows_list[i]), columns)\n",
    "    start = time.time()\n",
    "    A, Q, R, persisted = direct_TSQR_persist(data,int(num_blocks[i]), is_random = True)\n",
    "    Q_ = Q.compute()\n",
    "    R_ = R.compute()\n",
    "    end = time.time()\n",
    "    time_list_persist[i] = ((end - start)*1000)\n",
    "    memory_relative[i] = persisted.nbytes/dask_data.nbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b090ae1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(rows_list,time_list_direct,'o', linestyle='dotted',label='No persist')\n",
    "plt.plot(rows_list,time_list_persist,'o', linestyle='dotted',label='Persist')\n",
    "plt.xscale('log')\n",
    "plt.xlabel('# of rows of the hole matrix')\n",
    "plt.ylabel('time [ms]')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033da60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_relative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b08b8f",
   "metadata": {},
   "source": [
    "Using one persist lowers considerably the time and only its memory usage is 1/1000 of the original matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981a986f",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940d864d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
